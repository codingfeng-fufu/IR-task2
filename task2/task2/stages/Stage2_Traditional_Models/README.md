# Stage2: ä¼ ç»Ÿæ¨¡å‹å®ç°

**æ—¶é—´**ï¼š2024å¹´11æœˆ15æ—¥  
**ç›®æ ‡**ï¼šå®ç°ä¸‰ç§åŸºç¡€åˆ†ç±»æ–¹æ³•ï¼ˆæœ´ç´ è´å¶æ–¯ã€Word2Vec+SVMã€BERTï¼‰

## ğŸ“ æ–‡ä»¶åˆ—è¡¨

| æ–‡ä»¶ | è¡Œæ•° | åŠŸèƒ½ | æ€§èƒ½ |
|------|------|------|------|
| `naive_bayes_classifier.py` | 273 | æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨V1 | 73.46% |
| `word2vec_svm_classifier.py` | 450 | Word2Vec+SVMåˆ†ç±»å™¨ | 82.99% |
| `bert_classifier.py` | 348 | BERTåŸºç¡€åˆ†ç±»å™¨ | 87.91% |

## ğŸ¯ é˜¶æ®µæˆæœ

### 1. æœ´ç´ è´å¶æ–¯V1 (naive_bayes_classifier.py)
**æ€§èƒ½**ï¼šå‡†ç¡®ç‡ 73.46%ï¼ŒF1 78.82%

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- TF-IDFç‰¹å¾æå–ï¼ˆ5,000ç»´ï¼‰
- N-gramèŒƒå›´ï¼š(1,2) - unigram + bigram
- åˆ†ç±»å™¨ï¼šMultinomialNBï¼ˆalpha=1.0ï¼‰
- ç®€å•ç›´æ¥çš„å®ç°

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from naive_bayes_classifier import NaiveBayesClassifier

classifier = NaiveBayesClassifier(max_features=5000, ngram_range=(1, 2))
classifier.train(train_titles, train_labels)
predictions = classifier.predict(test_titles)
```

### 2. Word2Vec + SVM (word2vec_svm_classifier.py)
**æ€§èƒ½**ï¼šå‡†ç¡®ç‡ 82.99%ï¼ŒF1 85.74%

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- Gensim Word2Vecè®­ç»ƒè¯å‘é‡ï¼ˆ100ç»´ï¼‰
- å¥å­è¡¨ç¤ºï¼šè¯å‘é‡å¹³å‡
- SVMåˆ†ç±»å™¨ï¼šLinearSVC
- æ”¯æŒå¢é‡è®­ç»ƒ

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from word2vec_svm_classifier import Word2VecSVMClassifier

classifier = Word2VecSVMClassifier(vector_size=100, window=5)
classifier.train(train_titles, train_labels)
predictions = classifier.predict(test_titles)
```

### 3. BERTåŸºç¡€ç‰ˆ (bert_classifier.py)
**æ€§èƒ½**ï¼šå‡†ç¡®ç‡ 87.91%ï¼ŒF1 89.59%

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨ `bert-base-uncased` é¢„è®­ç»ƒæ¨¡å‹
- åºåˆ—æœ€å¤§é•¿åº¦ï¼š64 tokens
- è®­ç»ƒï¼š3 epochsï¼Œbatch_size 16
- ä½¿ç”¨AdamWä¼˜åŒ–å™¨

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from bert_classifier import BERTClassifier

classifier = BERTClassifier(model_name='bert-base-uncased', max_length=64)
classifier.train(train_titles, train_labels, epochs=3, batch_size=16)
predictions = classifier.predict(test_titles)
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | å‡†ç¡®ç‡ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1 | è®­ç»ƒæ—¶é—´ |
|------|--------|--------|--------|-----|----------|
| æœ´ç´ è´å¶æ–¯V1 | 73.46% | 73.59% | 84.86% | 78.82% | ~2åˆ†é’Ÿ |
| Word2Vec+SVM | 82.99% | 85.84% | 85.58% | 85.74% | ~10åˆ†é’Ÿ |
| BERTåŸºç¡€ç‰ˆ | 87.91% | 90.29% | 88.35% | 89.59% | ~1å°æ—¶ |

## ğŸ” æŠ€æœ¯åˆ†æ

### ä¸ºä»€ä¹ˆBERTè¡¨ç°æœ€å¥½ï¼Ÿ
1. **ä¸Šä¸‹æ–‡ç†è§£**ï¼šBERTæ•æ‰é•¿è·ç¦»ä¾èµ–
2. **é¢„è®­ç»ƒçŸ¥è¯†**ï¼šåœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šé¢„è®­ç»ƒ
3. **æ·±å±‚è¡¨ç¤º**ï¼š12å±‚Transformerç¼–ç å™¨

### ä¸ºä»€ä¹ˆæœ´ç´ è´å¶æ–¯è¾ƒå¼±ï¼Ÿ
1. **ç‰¹å¾ç‹¬ç«‹å‡è®¾**ï¼šå¿½ç•¥è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»
2. **ç®€å•ç‰¹å¾**ï¼šä»…ä½¿ç”¨TF-IDFï¼Œæ— è¯­ä¹‰ä¿¡æ¯
3. **çº¿æ€§æ¨¡å‹**ï¼šè¡¨è¾¾èƒ½åŠ›æœ‰é™

### Word2Vec+SVMçš„ä¸­åº¸è¡¨ç°
- âœ… ä¼˜ç‚¹ï¼šå¼•å…¥è¯å‘é‡è¯­ä¹‰ä¿¡æ¯
- âŒ ç¼ºç‚¹ï¼šç®€å•å¹³å‡ä¸¢å¤±è¯åºä¿¡æ¯

## ğŸ”— åç»­ä¼˜åŒ–

åŸºäºæ­¤é˜¶æ®µçš„ç»“æœï¼Œåç»­è¿›è¡Œäº†ï¼š
- **Stage3**ï¼šæœ´ç´ è´å¶æ–¯æ·±åº¦ä¼˜åŒ–ï¼ˆ73.46% â†’ 79.20%ï¼‰
- **Stage4**ï¼šBERTé«˜çº§ä¼˜åŒ–ï¼ˆ87.91% â†’ 89.04%ï¼‰

## ğŸ’» ä»£ç ç»Ÿè®¡

- **æ€»è¡Œæ•°**ï¼š~1,400è¡Œ
- **æ–‡ä»¶æ•°**ï¼š3ä¸ª
- **å¹³å‡æ¯ä¸ªæ¨¡å‹**ï¼š~467è¡Œ

---

**è¯´æ˜**ï¼šè¿™ä¸‰ä¸ªæ–‡ä»¶æ˜¯æ•´ä¸ªé¡¹ç›®çš„åŸºçŸ³ï¼Œæ‰€æœ‰åç»­ä¼˜åŒ–éƒ½åŸºäºè¿™äº›åŸºç¡€å®ç°ã€‚
