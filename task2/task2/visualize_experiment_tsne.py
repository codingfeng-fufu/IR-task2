"""
visualize_experiment_tsne.py
=============================
ä¸º run_bert_experiments.py ç”Ÿæˆçš„æ‰€æœ‰å®éªŒæ¨¡å‹ç”Ÿæˆ t-SNE å¯è§†åŒ–å›¾

ç”¨æ³•:
    python visualize_experiment_tsne.py
"""

import os
import sys
import json
import numpy as np
from typing import List, Dict
from data_loader import DataLoader as TitleDataLoader
from train_bert_optimized_v2 import OptimizedBERTClassifier
from visualizer import ResultVisualizer
from tqdm import tqdm


def visualize_all_experiments(
    test_titles: List[str],
    test_labels: List[int],
    script_dir: str,
    output_dir: str = 'output/bert_experiments'
):
    """ä¸ºæ‰€æœ‰å®éªŒæ¨¡å‹ç”Ÿæˆ t-SNE å¯è§†åŒ–"""

    # å®éªŒé…ç½® (éœ€è¦ä¸ run_bert_experiments.py ä¿æŒä¸€è‡´)
    experiments = [
        {
            'name': 'exp1_bert_base_baseline',
            'display_name': 'BERT-base (Baseline)',
            'model_name': 'bert-base',
            'max_length': 64
        },
        {
            'name': 'exp2_scibert_focal',
            'display_name': 'SciBERT + Focal Loss',
            'model_name': 'scibert',
            'max_length': 96
        },
        {
            'name': 'exp3_roberta_weighted',
            'display_name': 'RoBERTa + Weighted CE',
            'model_name': 'roberta',
            'max_length': 96
        },
        {
            'name': 'exp5_scibert_maxlen128',
            'display_name': 'SciBERT (MaxLen=128)',
            'model_name': 'scibert',
            'max_length': 128
        }
    ]

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # ä»æµ‹è¯•é›†ä¸­é‡‡æ · (t-SNE è®¡ç®—é‡å¤§ï¼Œé‡‡æ ·å¯ä»¥åŠ é€Ÿ)
    sample_size = min(500, len(test_titles))
    indices = np.random.RandomState(42).choice(len(test_titles), sample_size, replace=False)
    sampled_titles = [test_titles[i] for i in indices]
    sampled_labels = [test_labels[i] for i in indices]

    print("\n" + "="*100)
    print(" ğŸ¨ ä¸º BERT å®éªŒç”Ÿæˆ t-SNE å¯è§†åŒ–")
    print("="*100)
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_titles)}")
    print(f"é‡‡æ ·å¤§å°: {sample_size}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # å¯¹æ¯ä¸ªå®éªŒç”Ÿæˆ t-SNE
    successful_visualizations = []
    failed_visualizations = []

    for exp in experiments:
        print("\n" + "-"*100)
        print(f" ğŸ“Š å¤„ç†å®éªŒ: {exp['display_name']}")
        print("-"*100)

        # æ¨¡å‹è·¯å¾„ (ä¼˜å…ˆä½¿ç”¨ _best.pt, å¦åˆ™ä½¿ç”¨ .pt)
        model_path_best = os.path.join(script_dir, f"models/experiments/{exp['name']}_best.pt")
        model_path_final = os.path.join(script_dir, f"models/experiments/{exp['name']}.pt")

        if os.path.exists(model_path_best):
            model_path = model_path_best
            print(f"âœ“ æ‰¾åˆ°æœ€ä½³æ¨¡å‹: {exp['name']}_best.pt")
        elif os.path.exists(model_path_final):
            model_path = model_path_final
            print(f"âœ“ æ‰¾åˆ°æœ€ç»ˆæ¨¡å‹: {exp['name']}.pt")
        else:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨!")
            failed_visualizations.append({
                'name': exp['name'],
                'error': 'Model file not found'
            })
            continue

        try:
            # åˆ›å»ºåˆ†ç±»å™¨å¹¶åŠ è½½æ¨¡å‹
            classifier = OptimizedBERTClassifier(
                model_name=exp['model_name'],
                max_length=exp['max_length'],
                model_path=model_path
            )

            # åŠ è½½æ¨¡å‹
            if not classifier.load_model():
                print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥!")
                failed_visualizations.append({
                    'name': exp['name'],
                    'error': 'Failed to load model'
                })
                continue

            # æ‰‹åŠ¨è®¾ç½® is_trained æ ‡å¿— (ä¿®å¤åŠ è½½åçš„çŠ¶æ€)
            classifier.is_trained = True
            print(f"âœ“ æ¨¡å‹çŠ¶æ€å·²è®¾ç½®ä¸ºå·²è®­ç»ƒ")

            # è·å–ç‰¹å¾å‘é‡
            print(f"æå–ç‰¹å¾å‘é‡ (æ ·æœ¬æ•°: {sample_size})...")
            feature_vectors = classifier.get_feature_vectors(sampled_titles)
            print(f"âœ“ ç‰¹å¾å‘é‡ç»´åº¦: {feature_vectors.shape}")

            # ç”Ÿæˆ t-SNE å¯è§†åŒ–
            save_path = os.path.join(output_dir, f"tsne_{exp['name']}.png")
            ResultVisualizer.visualize_embeddings_tsne(
                vectors=feature_vectors,
                labels=sampled_labels,
                title=exp['display_name'],
                save_path=save_path,
                perplexity=30,
                n_iter=1000
            )

            print(f"âœ“ t-SNE å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
            successful_visualizations.append({
                'name': exp['name'],
                'display_name': exp['display_name'],
                'path': save_path
            })

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            failed_visualizations.append({
                'name': exp['name'],
                'error': str(e)
            })

    # æ‰“å°æ€»ç»“
    print("\n\n" + "="*100)
    print(" ğŸ“Š t-SNE å¯è§†åŒ–ç”Ÿæˆæ€»ç»“")
    print("="*100)

    print(f"\nâœ“ æˆåŠŸç”Ÿæˆ: {len(successful_visualizations)} ä¸ªå¯è§†åŒ–")
    for item in successful_visualizations:
        print(f"  - {item['display_name']}: {item['path']}")

    if failed_visualizations:
        print(f"\nâŒ å¤±è´¥: {len(failed_visualizations)} ä¸ª")
        for item in failed_visualizations:
            print(f"  - {item['name']}: {item['error']}")

    # ä¿å­˜æ€»ç»“åˆ° JSON
    summary = {
        'successful': successful_visualizations,
        'failed': failed_visualizations,
        'total': len(experiments),
        'sample_size': sample_size
    }

    summary_path = os.path.join(output_dir, 'tsne_summary.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ æ€»ç»“å·²ä¿å­˜: {summary_path}")

    return successful_visualizations, failed_visualizations


def main():
    """ä¸»å‡½æ•°"""

    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\n" + "="*100)
    print(" ğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®")
    print("="*100)
    print(f"è„šæœ¬ç›®å½•: {script_dir}")

    _, _, test_titles, test_labels = TitleDataLoader.prepare_dataset(
        os.path.join(script_dir, 'data/positive.txt'),
        os.path.join(script_dir, 'data/negative.txt'),
        os.path.join(script_dir, 'data/testSet-1000.xlsx')
    )

    if len(test_titles) == 0:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®!")
        return

    print(f"âœ“ æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ: {len(test_titles)} æ ·æœ¬")

    # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
    visualize_all_experiments(
        test_titles,
        test_labels,
        script_dir,
        output_dir=os.path.join(script_dir, 'output/bert_experiments')
    )

    print("\n" + "="*100)
    print(" âœ“ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
    print("="*100)


if __name__ == "__main__":
    main()
